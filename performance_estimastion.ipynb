{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from model_train import *\n",
    "from torch.optim import SGD,Adam\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(1024, kernel_regularizer = 'l2', activation = 'relu', input_shape=(1*18,)))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='msle',\n",
    "                  metrics=['mae', 'msle'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\39320\\\\Progetti\\\\bike\\\\dataset\\\\mae_drop.feather'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_feather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmae_drop.feather\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\39320\\netlov\\lib\\site-packages\\pandas\\io\\feather_format.py:126\u001B[0m, in \u001B[0;36mread_feather\u001B[1;34m(path, columns, use_threads, storage_options)\u001B[0m\n\u001B[0;32m    123\u001B[0m import_optional_dependency(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m feather\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m    128\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m feather\u001B[38;5;241m.\u001B[39mread_feather(\n\u001B[0;32m    131\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle, columns\u001B[38;5;241m=\u001B[39mcolumns, use_threads\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m(use_threads)\n\u001B[0;32m    132\u001B[0m     )\n",
      "File \u001B[1;32mc:\\users\\39320\\netlov\\lib\\site-packages\\pandas\\io\\common.py:710\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    701\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    702\u001B[0m             handle,\n\u001B[0;32m    703\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    706\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    707\u001B[0m         )\n\u001B[0;32m    708\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    709\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 710\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    711\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    713\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\39320\\\\Progetti\\\\bike\\\\dataset\\\\mae_drop.feather'"
     ]
    }
   ],
   "source": [
    "df = pd.read_feather(os.path.join(DATA_DIR,'mae_drop.feather'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "temp = pd.DataFrame(encoder.fit_transform(df['step'].values.reshape(-1,1)), columns = ['step'+str(el) for el in range(1,15)])\n",
    "df_encoded = df.drop('step', axis = 1).merge(temp, left_index = True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\AppData\\Local\\Temp\\ipykernel_17496\\1082319244.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean = df_encoded.mean(axis = 0)[['mae','dropout']].values # [mae_mean, dropout_mean]\n",
      "C:\\Users\\39320\\AppData\\Local\\Temp\\ipykernel_17496\\1082319244.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  var = df_encoded.var(axis = 0)[['mae','dropout']].values # [mae_var, dropout_var]\n"
     ]
    }
   ],
   "source": [
    "mean = df_encoded.mean(axis = 0)[['mae','dropout']].values # [mae_mean, dropout_mean]\n",
    "var = df_encoded.var(axis = 0)[['mae','dropout']].values # [mae_var, dropout_var]\n",
    "df_encoded['mae'] = (df_encoded['mae'] - mean[0])/var[0]\n",
    "df_encoded['dropout'] = (df_encoded['dropout'] - mean[1])/var[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "train,test = train_test_split(df_encoded,test_size = 0.3, random_state = 1)\n",
    "train_dataset = MaeDataset(train)\n",
    "test_dataset = MaeDataset(test)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size = 32,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size = 32,shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# model's parameters\n",
    "lr = 0.05\n",
    "num_epochs = 30\n",
    "log_interval = 100\n",
    "\n",
    "# model\n",
    "model = MLP(15,200,15)\n",
    "\n",
    "# Optimization\n",
    "optimizer = Adam(model.parameters(), lr = lr, weight_decay = 0.0001)\n",
    "# Learning Rate schedule\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "           dropout  step1  step2  step3  step4  step5  step6  step7  step8  \\\n4704  2.398107e+01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n5570  8.890094e+01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n250   3.158635e+02    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n1727  3.923048e+02    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n2610  9.352842e+02    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \n...            ...    ...    ...    ...    ...    ...    ...    ...    ...   \n2139  2.621893e+02    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n5061  2.403092e+06    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n1542  2.445182e+01    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n2991  2.446136e+02    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n1433  7.957508e+00    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \n\n      step9  step10  step11  step12  step13  step14  \n4704    0.0     0.0     0.0     1.0     0.0     0.0  \n5570    0.0     0.0     0.0     0.0     0.0     1.0  \n250     0.0     0.0     0.0     0.0     0.0     0.0  \n1727    0.0     0.0     0.0     0.0     0.0     0.0  \n2610    0.0     0.0     0.0     0.0     0.0     0.0  \n...     ...     ...     ...     ...     ...     ...  \n2139    0.0     0.0     0.0     0.0     0.0     0.0  \n5061    0.0     0.0     0.0     0.0     1.0     0.0  \n1542    0.0     0.0     0.0     0.0     0.0     0.0  \n2991    0.0     0.0     0.0     0.0     0.0     0.0  \n1433    0.0     0.0     0.0     0.0     0.0     0.0  \n\n[1680 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dropout</th>\n      <th>step1</th>\n      <th>step2</th>\n      <th>step3</th>\n      <th>step4</th>\n      <th>step5</th>\n      <th>step6</th>\n      <th>step7</th>\n      <th>step8</th>\n      <th>step9</th>\n      <th>step10</th>\n      <th>step11</th>\n      <th>step12</th>\n      <th>step13</th>\n      <th>step14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4704</th>\n      <td>2.398107e+01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>8.890094e+01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>3.158635e+02</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>3.923048e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2610</th>\n      <td>9.352842e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2139</th>\n      <td>2.621893e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5061</th>\n      <td>2.403092e+06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1542</th>\n      <td>2.445182e+01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2991</th>\n      <td>2.446136e+02</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1433</th>\n      <td>7.957508e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1680 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,2:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\39320\\netlov\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\39320\\netlov\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6684 \n",
      "Epoch: 2  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2050 \n",
      "Epoch: 3  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2339 \n",
      "Epoch: 4  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.4431 \n",
      "Epoch: 5  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6145 \n",
      "Epoch: 6  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 7.0864 \n",
      "Epoch: 7  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.7274 \n",
      "Epoch: 8  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 8.2266 \n",
      "Epoch: 9  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 7.6057 \n",
      "Epoch: 10  Lr: 0.00625000  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 7.9095 \n",
      "Epoch: 11  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6404 \n",
      "Epoch: 12  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 9.6882 \n",
      "Epoch: 13  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 8.7414 \n",
      "Epoch: 14  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 9.8340 \n",
      "Epoch: 15  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6177 \n",
      "Epoch: 16  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6863 \n",
      "Epoch: 17  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2982 \n",
      "Epoch: 18  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2688 \n",
      "Epoch: 19  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.6533 \n",
      "Epoch: 20  Lr: 0.00312500  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2371 \n",
      "Epoch: 21  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 7.6516 \n",
      "Epoch: 22  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.4365 \n",
      "Epoch: 23  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.4049 \n",
      "Epoch: 24  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.5870 \n",
      "Epoch: 25  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.4036 \n",
      "Epoch: 26  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.3792 \n",
      "Epoch: 27  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2644 \n",
      "Epoch: 28  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.3517 \n",
      "Epoch: 29  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2580 \n",
      "Epoch: 30  Lr: 0.00156250  Loss: Train = [0.0004] - Val = [0.0000]  MAE: Train = [0.02] - Val = [0.02]  Time one epoch (s): 6.2236 \n",
      "Time for 30 epochs (s): 208.353\n"
     ]
    }
   ],
   "source": [
    "statistics = training_loop(num_epochs, optimizer, scheduler,\n",
    "                           log_interval, model, train_loader,\n",
    "                           test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss:  0.00043 epoch: 21.\n",
      " \n",
      "Best mae: 0.02104 epoch: 27\n"
     ]
    }
   ],
   "source": [
    "best_epoch_loss = np.argmin(statistics['loss_values_val']) + 1\n",
    "best_loss= statistics['loss_values_val'][best_epoch_loss - 1]\n",
    "\n",
    "best_epoch_mae = np.argmin(statistics['val_mae_values']) + 1\n",
    "best_mae= statistics['val_mae_values'][best_epoch_loss - 1]\n",
    "\n",
    "print(f'Best val loss: {best_loss: .5f} epoch: {best_epoch_loss}.\\n \\n'\n",
    "      f'Best mae: {best_mae:.5f} epoch: {best_epoch_mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\AppData\\Local\\Temp\\ipykernel_17496\\3850566496.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(x,dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = []\n",
    "    for el in range(len(test)):\n",
    "        x = test.iloc[el,2:]\n",
    "        y = test.iloc[el,1]\n",
    "\n",
    "        x = torch.tensor(x,dtype=torch.float32)\n",
    "        y = torch.tensor(x,dtype=torch.float32)\n",
    "\n",
    "        prediction.append(model(x).detach().numpy())\n",
    "\n",
    "res = pd.DataFrame([np.array(prediction).reshape(-1),test['mae'].values]).T\n",
    "res.rename(columns = {0:'pred',1:'real'}, inplace = True)\n",
    "res = res.apply(lambda x: x * var[0] + mean[0])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.scatter(list(res.index), res['real'], label = 'real')\n",
    "plt.scatter(list(res.index), res['pred'], label = 'pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "              pred          real\n0     9.142441e-11 -2.043755e-09\n1     9.142441e-11 -2.046568e-09\n2     9.142441e-11 -2.015268e-09\n3     9.142441e-11 -1.697801e-09\n4     9.142441e-11 -2.026086e-09\n...            ...           ...\n1675  9.142441e-11 -1.959700e-09\n1676  9.142441e-11 -1.977075e-10\n1677  9.142441e-11 -2.048829e-09\n1678  9.142441e-11 -2.051797e-09\n1679  9.142441e-11 -2.051598e-09\n\n[1680 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred</th>\n      <th>real</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.142441e-11</td>\n      <td>-2.043755e-09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.142441e-11</td>\n      <td>-2.046568e-09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.142441e-11</td>\n      <td>-2.015268e-09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.142441e-11</td>\n      <td>-1.697801e-09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.142441e-11</td>\n      <td>-2.026086e-09</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1675</th>\n      <td>9.142441e-11</td>\n      <td>-1.959700e-09</td>\n    </tr>\n    <tr>\n      <th>1676</th>\n      <td>9.142441e-11</td>\n      <td>-1.977075e-10</td>\n    </tr>\n    <tr>\n      <th>1677</th>\n      <td>9.142441e-11</td>\n      <td>-2.048829e-09</td>\n    </tr>\n    <tr>\n      <th>1678</th>\n      <td>9.142441e-11</td>\n      <td>-2.051797e-09</td>\n    </tr>\n    <tr>\n      <th>1679</th>\n      <td>9.142441e-11</td>\n      <td>-2.051598e-09</td>\n    </tr>\n  </tbody>\n</table>\n<p>1680 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}